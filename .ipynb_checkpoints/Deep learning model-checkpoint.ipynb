{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81037327-c2b6-4879-bfef-cb6eae54cf9c",
   "metadata": {},
   "source": [
    "## get the data df from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c58ebf5d-22d7-4a93-af79-457258d7e54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63897, 10)\n",
      "[0 1 2 3 4]\n",
      "[2 0 3 1 4]\n",
      "[3 0 2 4 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6390, 5)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Soil_types_directory= 'C:/Users/user/Google Drive/TCD20/python/dataset/Soil types'\n",
    "data_image=pd.read_csv(os.path.join(Soil_types_directory,'all_image_64.csv'))\n",
    "data_image_mean=pd.read_csv(os.path.join(Soil_types_directory,'all_image_mean.csv'))\n",
    "data_image_Selecting=pd.read_csv(os.path.join(Soil_types_directory,'Selecting_image_64.csv'))\n",
    "\n",
    "\n",
    "\n",
    "data_image2=data_image.groupby(by=['classes']).sample(frac=0.1, random_state=42)\n",
    "print(data_image2.shape)\n",
    "\n",
    "\n",
    "x_data=data_image2[['r','g','b']]\n",
    "y_data=data_image2['classes2']\n",
    "print(y_data.unique())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.1, random_state=42)\n",
    "print(y_train.unique())\n",
    "print(y_test.unique())\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_encoded = to_categorical(y_train,num_classes=5)\n",
    "y_test_encoded = to_categorical(y_test,num_classes=5)\n",
    "y_test_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8c2c65-38b0-49f8-8320-14ea47d9b6da",
   "metadata": {},
   "source": [
    "## from df   fully connected network (FCNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "22c9c67a-ae13-4bb0-b5f0-aebbf313c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6160a85-52c6-48c8-9787-cc1f51dcc980",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "### Set up the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7e4ab56a-f097-4f39-a0cf-2cf60997ca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 16)                64        \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "model.add(Input(shape=(3,)))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "#model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_dtype=True, show_shapes=True, show_layer_names=True, to_file='model_1.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d949e70-711d-4415-a06d-0af8db664dff",
   "metadata": {},
   "source": [
    "### Compile ane fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "557a7d50-0547-4a80-aef3-1c1f6550d012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 9s 1ms/step - loss: 1.6711 - accuracy: 0.2337 - val_loss: 1.6472 - val_accuracy: 0.3003\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 8s 1ms/step - loss: 1.6604 - accuracy: 0.2397 - val_loss: 1.6381 - val_accuracy: 0.2438\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 8s 1ms/step - loss: 1.7177 - accuracy: 0.2033 - val_loss: 1.6620 - val_accuracy: 0.1919\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 9s 2ms/step - loss: 1.7203 - accuracy: 0.2074 - val_loss: 1.8594 - val_accuracy: 0.2438\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 9s 2ms/step - loss: 1.7179 - accuracy: 0.2063 - val_loss: 1.6593 - val_accuracy: 0.2518\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 9s 2ms/step - loss: 1.7129 - accuracy: 0.2065 - val_loss: 1.8808 - val_accuracy: 0.1869\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 8s 1ms/step - loss: 1.7077 - accuracy: 0.2118 - val_loss: 1.6297 - val_accuracy: 0.2016\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 10s 2ms/step - loss: 1.6465 - accuracy: 0.2533 - val_loss: 1.6965 - val_accuracy: 0.2438\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 9s 1ms/step - loss: 1.7190 - accuracy: 0.2042 - val_loss: 1.6211 - val_accuracy: 0.1870\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 9s 1ms/step - loss: 1.7309 - accuracy: 0.2053 - val_loss: 1.8585 - val_accuracy: 0.1826\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 8s 1ms/step - loss: 1.7269 - accuracy: 0.2016 - val_loss: 1.8186 - val_accuracy: 0.1870\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 9s 1ms/step - loss: 1.7230 - accuracy: 0.2027 - val_loss: 1.6560 - val_accuracy: 0.2438\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 9s 2ms/step - loss: 1.7205 - accuracy: 0.2052 - val_loss: 1.6421 - val_accuracy: 0.1919\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 9s 2ms/step - loss: 1.7298 - accuracy: 0.2051 - val_loss: 1.6740 - val_accuracy: 0.2438\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 9s 2ms/step - loss: 1.7259 - accuracy: 0.2024 - val_loss: 1.6801 - val_accuracy: 0.1947\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 8s 1ms/step - loss: 1.7210 - accuracy: 0.2070 - val_loss: 1.9536 - val_accuracy: 0.1947\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 9s 2ms/step - loss: 1.7244 - accuracy: 0.2048 - val_loss: 1.7400 - val_accuracy: 0.1919\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 8s 1ms/step - loss: 1.7217 - accuracy: 0.2076 - val_loss: 1.7664 - val_accuracy: 0.1919\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 9s 2ms/step - loss: 1.7254 - accuracy: 0.2051 - val_loss: 1.7916 - val_accuracy: 0.2438\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 8s 1ms/step - loss: 1.7220 - accuracy: 0.2048 - val_loss: 1.6435 - val_accuracy: 0.1919\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.671131</td>\n",
       "      <td>0.233693</td>\n",
       "      <td>1.647216</td>\n",
       "      <td>0.300313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.660356</td>\n",
       "      <td>0.239693</td>\n",
       "      <td>1.638102</td>\n",
       "      <td>0.243818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.717730</td>\n",
       "      <td>0.203297</td>\n",
       "      <td>1.661982</td>\n",
       "      <td>0.191862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.720333</td>\n",
       "      <td>0.207383</td>\n",
       "      <td>1.859385</td>\n",
       "      <td>0.243818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.717904</td>\n",
       "      <td>0.206253</td>\n",
       "      <td>1.659253</td>\n",
       "      <td>0.251800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.712891</td>\n",
       "      <td>0.206531</td>\n",
       "      <td>1.880836</td>\n",
       "      <td>0.186854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.707738</td>\n",
       "      <td>0.211835</td>\n",
       "      <td>1.629740</td>\n",
       "      <td>0.201565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.646540</td>\n",
       "      <td>0.253308</td>\n",
       "      <td>1.696462</td>\n",
       "      <td>0.243818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.718984</td>\n",
       "      <td>0.204201</td>\n",
       "      <td>1.621066</td>\n",
       "      <td>0.187011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.730866</td>\n",
       "      <td>0.205349</td>\n",
       "      <td>1.858480</td>\n",
       "      <td>0.182629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.726851</td>\n",
       "      <td>0.201593</td>\n",
       "      <td>1.818639</td>\n",
       "      <td>0.187011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.723019</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>1.655962</td>\n",
       "      <td>0.243818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.720486</td>\n",
       "      <td>0.205175</td>\n",
       "      <td>1.642138</td>\n",
       "      <td>0.191862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.729826</td>\n",
       "      <td>0.205053</td>\n",
       "      <td>1.673986</td>\n",
       "      <td>0.243818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.725866</td>\n",
       "      <td>0.202410</td>\n",
       "      <td>1.680130</td>\n",
       "      <td>0.194679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.720978</td>\n",
       "      <td>0.207001</td>\n",
       "      <td>1.953605</td>\n",
       "      <td>0.194679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.724400</td>\n",
       "      <td>0.204758</td>\n",
       "      <td>1.739976</td>\n",
       "      <td>0.191862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.721690</td>\n",
       "      <td>0.207644</td>\n",
       "      <td>1.766400</td>\n",
       "      <td>0.191862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.725382</td>\n",
       "      <td>0.205123</td>\n",
       "      <td>1.791636</td>\n",
       "      <td>0.243818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.722037</td>\n",
       "      <td>0.204827</td>\n",
       "      <td>1.643513</td>\n",
       "      <td>0.191862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.671131  0.233693  1.647216      0.300313\n",
       "1   1.660356  0.239693  1.638102      0.243818\n",
       "2   1.717730  0.203297  1.661982      0.191862\n",
       "3   1.720333  0.207383  1.859385      0.243818\n",
       "4   1.717904  0.206253  1.659253      0.251800\n",
       "5   1.712891  0.206531  1.880836      0.186854\n",
       "6   1.707738  0.211835  1.629740      0.201565\n",
       "7   1.646540  0.253308  1.696462      0.243818\n",
       "8   1.718984  0.204201  1.621066      0.187011\n",
       "9   1.730866  0.205349  1.858480      0.182629\n",
       "10  1.726851  0.201593  1.818639      0.187011\n",
       "11  1.723019  0.202688  1.655962      0.243818\n",
       "12  1.720486  0.205175  1.642138      0.191862\n",
       "13  1.729826  0.205053  1.673986      0.243818\n",
       "14  1.725866  0.202410  1.680130      0.194679\n",
       "15  1.720978  0.207001  1.953605      0.194679\n",
       "16  1.724400  0.204758  1.739976      0.191862\n",
       "17  1.721690  0.207644  1.766400      0.191862\n",
       "18  1.725382  0.205123  1.791636      0.243818\n",
       "19  1.722037  0.204827  1.643513      0.191862"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=0.05)\n",
    "\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='accuracy',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "epochs=20\n",
    "history=model.fit(X_train, y_train_encoded,\n",
    "          validation_data=(X_test,y_test_encoded ),\n",
    "          batch_size=10, epochs=epochs, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history_df=pd.DataFrame(history.history)\n",
    "history_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d19dc34-a2df-45c0-b282-ae6f2d6eeb0f",
   "metadata": {},
   "source": [
    "### Summary model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8ac72058-5ffc-466a-8b3b-134d2bfc7ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import  confusion_matrix,multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def model_predict(model,X,Y,labels):\n",
    "    # predict\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "    # Calculate classification report\n",
    "    classification_report1 = classification_report(Y, y_pred_classes,labels=labels,output_dict=True)\n",
    "    # Calculate confusion_matrix\n",
    "    multi_confusion_matrix1=multilabel_confusion_matrix(Y, y_pred_classes,labels=labels)\n",
    "    confusion_matrix1= confusion_matrix(Y, y_pred_classes,labels=labels)\n",
    "    \n",
    "    return  classification_report1,  confusion_matrix1,multi_confusion_matrix1\n",
    " \n",
    "   \n",
    "def plot_model_results(model_history_df,epochs):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def model_summary(classification_report,multi_confusion_matrix,confusion_matrix,classes):\n",
    "    \n",
    "    # classification_report to DataFrame\n",
    "    #required_fields=['Black Soil', 'Cinder Soil', 'Laterite Soil', 'Peat Soil', 'Yellow Soil','macro avg', 'weighted avg']#, 'weighted avg'\n",
    "    required_fields=['0', '1', '2', '3', '4', 'macro avg', 'weighted avg']\n",
    "    classification_report_dict={k:v['precision'] for k,v in classification_report.items() if k in required_fields}\n",
    "    classification_report_dict.update({'accuracy':classification_report1['accuracy']})\n",
    "    classification_report_df=pd.DataFrame(classification_report_dict,index=['precision']).T\n",
    "    classification_report_df.index=['Black Soil', 'Cinder Soil', 'Laterite Soil', 'Peat Soil', 'Yellow Soil','macro avg', 'weighted avg','accuracy']\n",
    "    classification_report_df= classification_report_df.sort_values(by = 'precision', ascending=False)#\n",
    "    \n",
    "    # confusion_matrix to  DataFrame\n",
    "    dict_matrix=dict()\n",
    "    for i,l in zip(range(multi_confusion_matrix.shape[0]),classes):\n",
    "        cm=multi_confusion_matrix1[i,:,:]\n",
    "        df_cm = pd.DataFrame(cm,index= ['other',l], columns=['other',l])\n",
    "        #confusion_matrix, index=class_names, columns=class_names,\n",
    "        dict_matrix.update({l:df_cm})\n",
    "    \n",
    "    classes=['Black Soil', 'Cinder Soil', 'Laterite Soil', 'Peat Soil', 'Yellow Soil']\n",
    "    confusion_matrix_df= pd.DataFrame(confusion_matrix,index=classes, columns=classes)\n",
    "    return classification_report_df, dict_matrix, confusion_matrix_df\n",
    "\n",
    "\n",
    "labels=['Black Soil', 'Cinder Soil', 'Laterite Soil', 'Peat Soil', 'Yellow Soil']\n",
    "labels=[0,1,2,3,4]\n",
    "\n",
    "classification_report1,confusion_matrix1,multi_confusion_matrix1=model_predict(model,X_test, y_test,labels)\n",
    "classification_report_df, dict_matrix, confusion_matrix_df=model_summary(classification_report1,multi_confusion_matrix1,confusion_matrix1,labels)\n",
    "plot_model_results(history_df,epochs)\n",
    "\n",
    "\n",
    "print(classification_report_df)\n",
    "confusion_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "35a68af8-8da7-496d-94ba-3ecb72acfb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step\n",
      "              precision\n",
      "1              1.000000\n",
      "4              0.643991\n",
      "weighted avg   0.464981\n",
      "macro avg      0.464593\n",
      "2              0.391534\n",
      "accuracy       0.343036\n",
      "0              0.287441\n",
      "3              0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Black Soil</th>\n",
       "      <th>Cinder Soil</th>\n",
       "      <th>Laterite Soil</th>\n",
       "      <th>Peat Soil</th>\n",
       "      <th>Yellow Soil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Black Soil</th>\n",
       "      <td>737</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cinder Soil</th>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laterite Soil</th>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peat Soil</th>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yellow Soil</th>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Black Soil  Cinder Soil  Laterite Soil  Peat Soil  Yellow Soil\n",
       "Black Soil            737            0              3          0            4\n",
       "Cinder Soil           628            1              8          0            3\n",
       "Laterite Soil         393            0             74          0          135\n",
       "Peat Soil             556            0             23          0           15\n",
       "Yellow Soil           250            0             81          0          284"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9804b5e4-e251-49a1-b08b-d71d2eeb807f",
   "metadata": {},
   "source": [
    "## get the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ff5ca-3db5-43d3-9fe2-2940bb74ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "data_dir= 'C:/Users/user/Google Drive/TCD20/python/dataset/Soil types'\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "train_ds= tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names =image_soil.class_names\n",
    "print(class_names)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d13617-1c49-4621-91ef-dd25aba866bd",
   "metadata": {},
   "source": [
    "# from  image   Convolutional Neural Networks (CNNs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88cd2ed-9eba-431e-bc14-7689e3f7bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2e44a-045c-407c-924b-493d392ec2c8",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "### Set up the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e6200d-68bd-4433-b31b-5f51154627cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f7f33-02dc-46f7-bb57-d13675f9f4aa",
   "metadata": {},
   "source": [
    "### Compile ane fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a80436-e752-4b4f-a343-eb41863576d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec04257b-b206-4f60-a2aa-71e01d00ea1b",
   "metadata": {},
   "source": [
    "### Summary model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab611b90-2815-438f-a83f-705b6f3847c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26eb762-2d71-422b-86ec-4bb2ed590947",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(99):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8451e-cc5d-4a87-a66e-5d9f811bc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94dd195-ddbf-41bc-8b03-a0253e785564",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18969dd-c5dd-40f1-ad32-0fa6e33f75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52437f-44fe-46cb-b46f-107c72ee8d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
