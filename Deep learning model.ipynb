{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e125e56-3d5b-4a02-9806-ad5699457a34",
   "metadata": {},
   "source": [
    "## function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865a3ee-a594-4ecc-b3bb-cd7bd4be0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import  confusion_matrix,multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "def  TrainTestSplit(data):\n",
    "    print(data.shape) \n",
    "    x_data=data[['r','g','b']]\n",
    "    y_data=data['classes2']\n",
    "    print(y_data.unique())\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=42)\n",
    "    print(y_train.unique())\n",
    "    print(y_test.unique())\n",
    "    y_train_encoded = to_categorical(y_train,num_classes=5)\n",
    "    y_test_encoded = to_categorical(y_test,num_classes=5) \n",
    "    return X_train, X_test,y_train, y_test,  y_train_encoded,y_test_encoded\n",
    "\n",
    "\n",
    "def model_predict(model,X,Y,labels):\n",
    "    # predict\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "    # Calculate classification report\n",
    "    classification_report1 = classification_report(Y, y_pred_classes,labels=labels,output_dict=True)\n",
    "    # Calculate confusion_matrix\n",
    "    multi_confusion_matrix1=multilabel_confusion_matrix(Y, y_pred_classes,labels=labels)\n",
    "    confusion_matrix1= confusion_matrix(Y, y_pred_classes,labels=labels)\n",
    "    \n",
    "    return  classification_report1,  confusion_matrix1,multi_confusion_matrix1\n",
    " \n",
    "    \n",
    "    \n",
    "def model_summary(classification_report,multi_confusion_matrix,confusion_matrix,classes):\n",
    "    \n",
    "    # classification_report to DataFrame\n",
    "    #required_fields=['Black Soil', 'Cinder Soil', 'Laterite Soil', 'Peat Soil', 'Yellow Soil','macro avg', 'weighted avg']#, 'weighted avg'\n",
    "    required_fields=['0', '1', '2', '3', '4', 'macro avg', 'weighted avg']\n",
    "    classification_report_dict={k:v['precision'] for k,v in classification_report.items() if k in required_fields}\n",
    "    #classification_report_dict2={k:v['support'] for k,v in classification_report.items() if k in required_fields}\n",
    "    #classification_report_dict.update({'accuracy':classification_report['accuracy']})\n",
    "    classification_report_df=pd.DataFrame(classification_report_dict,index=['precision']).T\n",
    "    # classification_report_df.index=['Black Soil', 'Cinder Soil', 'Laterite Soil', 'Peat Soil', 'Yellow Soil','macro avg', 'weighted avg','accuracy']#,\n",
    "    classification_report_df.index=['Black Soil', 'Cinder Soil', 'Laterite Soil', 'Peat Soil', 'Yellow Soil','macro avg', 'weighted avg']#,\n",
    "    classification_report_df= classification_report_df.sort_values(by = 'precision', ascending=False)\n",
    "    # confusion_matrix to  DataFrame\n",
    "    classes=['Black Soil', 'Cinder Soil', 'Laterite Soil', 'Peat Soil', 'Yellow Soil']\n",
    "    dict_matrix=dict()\n",
    "    for i,l in zip(range(multi_confusion_matrix.shape[0]),classes):\n",
    "        cm=multi_confusion_matrix1[i,:,:]\n",
    "        df_cm = pd.DataFrame(cm,index= ['other',l], columns=['other',l])\n",
    "        #confusion_matrix, index=class_names, columns=class_names,\n",
    "        dict_matrix.update({l:df_cm})\n",
    "    \n",
    "    classes=['Black Soil', 'Cinder Soil', 'Laterite Soil', 'Peat Soil', 'Yellow Soil']\n",
    "    confusion_matrix_df= pd.DataFrame(confusion_matrix,index=classes, columns=classes)\n",
    "    return classification_report_df, dict_matrix, confusion_matrix_df\n",
    "   \n",
    "def plot_model_results(model_history_df):\n",
    "    acc =model_history_df['accuracy']\n",
    "    val_acc = model_history_df['val_accuracy']\n",
    "    loss =model_history_df['loss']\n",
    "    val_loss =model_history_df['val_loss']\n",
    "\n",
    "    epochs_range = range(model_history_df.shape[0])\n",
    "    fig,ax = plt.subplots(1,2,figsize=(20,12))\n",
    "    \n",
    "    ax[0].plot(epochs_range, acc, label='Training Accuracy')\n",
    "    ax[0].plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=40)\n",
    "    ax[0].tick_params(axis='both', which='minor', labelsize=25) \n",
    "    ax[0].legend(loc='lower right')\n",
    "    ax[0].set_title('Training and Validation Accuracy')\n",
    "\n",
    "    \n",
    "    ax[1].plot(epochs_range, loss, label='Training Loss')\n",
    "    ax[1].plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=40)\n",
    "    ax[1].tick_params(axis='both', which='minor', labelsize=25) \n",
    "    ax[1].legend(loc='upper right')\n",
    "    ax[1].set_title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "    return fig \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81037327-c2b6-4879-bfef-cb6eae54cf9c",
   "metadata": {},
   "source": [
    "# inport the data df from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f71904-9609-4a1f-8be8-70ac463fbca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Soil_types_directory= 'C:/Users/user/Google Drive/TCD20/python/final_project/Soil_Export'\n",
    "data_image=pd.read_csv(os.path.join(Soil_types_directory,'all_image_64.csv'))\n",
    "data_image_select_image=pd.read_csv(os.path.join(Soil_types_directory,'Selecting_image_64.csv'))\n",
    "data_image_cleaning=pd.read_csv(os.path.join(Soil_types_directory,'all_image_cleaning_128.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8c2c65-38b0-49f8-8320-14ea47d9b6da",
   "metadata": {},
   "source": [
    "# from df   fully connected network (FNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6160a85-52c6-48c8-9787-cc1f51dcc980",
   "metadata": {},
   "source": [
    "\n",
    "### Set up the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66ff4c2-fe8b-4db5-a385-5f7e4efdc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# Define a function that returns your TensorFlow model\n",
    "def create_FCNNsmodel():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(3,)))\n",
    "    model.add(Dense(16, activation='tanh'))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(16, activation='tanh'))\n",
    "    model.add(Dense(16, activation='tanh'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer , loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model=create_FCNNsmodel()\n",
    "model.summary()\n",
    "#optimizer = Adam(learning_rate=0.0001)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "#tf.keras.utils.plot_model(model, show_dtype=True, show_shapes=True, show_layer_names=True, to_file='model_1.png')\n",
    "\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='accuracy',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170e692-b5d2-405e-9dfc-8f58a516a7ef",
   "metadata": {},
   "source": [
    "## data image all pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d429e3-085d-4626-84c7-bb2e1f520c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "data_image2=data_image.groupby(by=['classes']).sample(frac=0.1, random_state=42)\n",
    "print(data_image2.shape)\n",
    "epochs=100\n",
    "X_train,X_test, y_train, y_test,y_train_encoded,y_test_encoded=  TrainTestSplit(data_image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8bf190-4fa4-4576-8c67-5934cdc316ec",
   "metadata": {},
   "source": [
    "### fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06289cd-2956-4b07-8990-386f270d18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train, y_train_encoded,\n",
    "          validation_data=(X_test,y_test_encoded ),\n",
    "          batch_size=16, epochs=epochs, callbacks=[early_stopping_monitor] \n",
    "          , verbose=True)\n",
    "\n",
    "history_df=pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d19dc34-a2df-45c0-b282-ae6f2d6eeb0f",
   "metadata": {},
   "source": [
    "### Summary model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b72c7-f69e-4a4b-8cdc-1034ce757445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f7e56-03fb-4b0c-a1fe-f8a48f8eea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels=['Black Soil', 'Cinder Soil', 'Laterite Soil', 'Peat Soil', 'Yellow Soil']\n",
    "labels=[0,1,2,3,4]\n",
    "\n",
    "classification_report1,confusion_matrix1,multi_confusion_matrix1=model_predict(model,X_test,y_test,labels)\n",
    "classification_report_df, dict_matrix, confusion_matrix_df=model_summary(classification_report1,multi_confusion_matrix1,confusion_matrix1,labels)\n",
    "f=plot_model_results(history_df)\n",
    "Soil_Export= 'C:/Users/user/Google Drive/TCD20/python/final_project/fig'       \n",
    "f.savefig(os.path.join(Soil_Export,'soil_image_dl.png'))      \n",
    "\n",
    "\n",
    "#classification_report_df\n",
    "print('### Yellow Soil ###')\n",
    "print(dict_matrix['Yellow Soil'])\n",
    "print('### Laterite Soil\t ###')\n",
    "print(dict_matrix['Laterite Soil'])\n",
    "print('### Black Soil ###')\n",
    "print(dict_matrix['Black Soil'])\n",
    "print('### Cinder Soill\t ###')\n",
    "print(dict_matrix['Cinder Soil'])\n",
    "print('### Peat Soil\t ###')\n",
    "print(dict_matrix['Peat Soil'])\n",
    "\n",
    "\n",
    "print(confusion_matrix_df)\n",
    "Soil_Export= 'C:/Users/user/Google Drive/TCD20/python/final_project/csv'   \n",
    "classification_report_df.to_csv(os.path.join(Soil_Export,'soil_image_dl.csv'))\n",
    "classification_report_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d01068a-6024-4148-929c-584099a25d31",
   "metadata": {},
   "source": [
    "## data image cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f946eb0d-c0e0-461b-a492-0b234e9c02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "data_image2=data_image_cleaning.groupby(by=['classes']).sample(frac=0.01, random_state=42)\n",
    "print(data_image2.shape)\n",
    "epochs=100\n",
    "X_train,X_test, y_train, y_test,y_train_encoded,y_test_encoded=  TrainTestSplit(data_image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9a2fda-ec56-4a8d-a225-afd094e59adb",
   "metadata": {},
   "source": [
    "### fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce2798-0019-46a3-982e-ad1d2c12fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train, y_train_encoded,\n",
    "          validation_data=(X_test,y_test_encoded ),\n",
    "          batch_size=16, epochs=epochs, callbacks=[early_stopping_monitor] \n",
    "          , verbose=True)\n",
    "\n",
    "history_df=pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f8e19c-85dc-4279-8ce8-ee7acea07e4e",
   "metadata": {},
   "source": [
    "### Summary model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27459adf-87cd-4d35-b26d-475e6305c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b884211-817b-4307-88f7-a85e42610235",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['Black Soil', 'Cinder Soil', 'Laterite Soil', 'Peat Soil', 'Yellow Soil']\n",
    "labels=[0,1,2,3,4]\n",
    "\n",
    "classification_report1,confusion_matrix1,multi_confusion_matrix1=model_predict(model,X_test,y_test,labels)\n",
    "classification_report_df, dict_matrix, confusion_matrix_df=model_summary(classification_report1,multi_confusion_matrix1,confusion_matrix1,labels)\n",
    "f=plot_model_results(history_df)\n",
    "Soil_Export= 'C:/Users/user/Google Drive/TCD20/python/final_project/fig'       \n",
    "f.savefig(os.path.join(Soil_Export,'soil_image_dl_a.png'))      \n",
    "\n",
    "\n",
    "#classification_report_df\n",
    "print('### Yellow Soil ###')\n",
    "print(dict_matrix['Yellow Soil'])\n",
    "print('### Laterite Soil\t ###')\n",
    "print(dict_matrix['Laterite Soil'])\n",
    "print('### Black Soil ###')\n",
    "print(dict_matrix['Black Soil'])\n",
    "print('### Cinder Soill\t ###')\n",
    "print(dict_matrix['Cinder Soil'])\n",
    "print('### Peat Soil\t ###')\n",
    "print(dict_matrix['Peat Soil'])\n",
    "\n",
    "\n",
    "print(confusion_matrix_df)\n",
    "Soil_Export= 'C:/Users/user/Google Drive/TCD20/python/final_project/csv'   \n",
    "classification_report_df.to_csv(os.path.join(Soil_Export,'soil_image_dl_a.csv'))\n",
    "classification_report_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042be64c-438f-40be-8069-2bd12f77daaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "214b63f4-b18e-4701-8b87-7b1a0e9b1adf",
   "metadata": {},
   "source": [
    "## optimization of batch and epochs\n",
    "### fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6412e-1698-42ef-a993-bbd242a8c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define a function that returns your TensorFlow model\n",
    "def create_FCNNsmodel():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(3,)))\n",
    "    model.add(Dense(16, activation='tanh'))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(16, activation='tanh'))\n",
    "    model.add(Dense(16, activation='tanh'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer , loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "keras_model = KerasClassifier(reate_FCNNsmodel)\n",
    "# Define the hyperparameter grid for the grid search\n",
    "param_grid = {\n",
    "    'batch_size': [8,10,16],\n",
    "    'epochs': [90,95,100,105,110,120]   \n",
    "     }\n",
    "\n",
    "# Perform grid search with cross-validation and include validation data and callbacks\n",
    "grid_search = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=5) \n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor (e.g., validation loss)\n",
    "    patience=3,  # Number of epochs to wait for improvement\n",
    "    restore_best_weights=True  # Restores the weights of the best epoch\n",
    "    )\n",
    "    callbacks = {\n",
    "    'early_stopping': early_stopping_monitor}    \n",
    "\n",
    "grid_search.fit(X_train, y_train_encoded, validation_data=(X_test,y_test_encoded), callbacks=callbacks)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.bdef Keras_Classifier(build_fn=create_FCNNsmodel):\n",
    "    # Wrap the TensorFlow model using KerasClassifier\n",
    "    keras_model = KerasClassifier(build_fn=build_fn)\n",
    "    # Define the hyperparameter grid for the grid search\n",
    "    param_grid = {\n",
    "    'batch_size': [8,10,16],\n",
    "    'epochs': [90,95,100,105,110,120]   \n",
    "     }\n",
    "\n",
    "    # Perform grid search with cross-validation and include validation data and callbacks\n",
    "    grid_search = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=5) \n",
    "    \n",
    "    early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor (e.g., validation loss)\n",
    "    patience=3,  # Number of epochs to wait for improvement\n",
    "    restore_best_weights=True  # Restores the weights of the best epoch\n",
    "    )\n",
    "    callbacks = {\n",
    "    'early_stopping': early_stopping_monitor}\n",
    "\n",
    "    return  grid_search, callbacksest_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Access the training and validation scores for each parameter combination\n",
    "                       \n",
    "cv_results = grid_search.cv_results_\n",
    "#train_scores = cv_results['mean_train_score']\n",
    "val_scores = cv_results['mean_test_score']\n",
    "\n",
    "# Print the training and validation scores for each parameter combination\n",
    "  \n",
    "a=pd.DataFrame()\n",
    "for val_score, params in zip( val_scores, cv_results['params']):\n",
    "   #print(f\" Validation Score: {val_score:.4f}, Params: {params}\")                             \n",
    "   b=pd.DataFrame(params,index=[0])\n",
    "   b=b.assign( val_score=val_score) \n",
    "   a=pd.concat([a,b])\n",
    "\n",
    "a=a.sort_values(by = 'val_score', ascending=False)\n",
    "a\n",
    "Soil_Export= 'C:/Users/user/Google Drive/TCD20/python/final_project/csv' \n",
    "a.to_csv(os.path.join(Soil_Export,'optimization of batch and epochsÂ¶.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967722da-b21c-4d65-9e23-12c8a2b852cf",
   "metadata": {},
   "source": [
    "## optimization of pramter\n",
    "## fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d80a3-0b1a-4927-804b-650855697410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_FCNNsmodel3(activation='relu', num_neurons=16,  dropout=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(3,)))\n",
    "    model.add(Dense(num_neurons, activation=activation))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(num_neurons, activation=activation))\n",
    "    model.add(Dense(num_neurons, activation=activation))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "keras_model = KerasClassifier(build_fn=create_FCNNsmodel3, batch_size=16, epochs=100)\n",
    "# Define the hyperparameter grid for the grid search\n",
    "param_grid = {\n",
    "    'activation': ['relu', 'tanh', 'sigmoid', 'linear'],\n",
    "    'num_neurons': [1, 5, 10,  20, 50],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create an instance of the EarlyStopping callback\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor (e.g., validation loss)\n",
    "    patience=3,  # Number of epochs to wait for improvement\n",
    "    restore_best_weights=True  # Restores the weights of the best epoch\n",
    ")\n",
    "\n",
    "# Perform grid search with cross-validation and include validation data and callbacks\n",
    "grid_search = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=5,verbose=2)\n",
    "grid_search.fit(X_train, y_train_encoded, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train_encoded, validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "cv_results = grid_search.cv_results_\n",
    "#train_scores = cv_results['mean_train_score']\n",
    "val_scores = cv_results['mean_test_score']\n",
    "\n",
    "# Print the training and validation scores for each parameter combination\n",
    "  \n",
    "history_df=pd.DataFrame()\n",
    "for val_score, params in zip( val_scores, cv_results['params']):\n",
    "   #print(f\" Validation Score: {val_score:.4f}, Params: {params}\")                             \n",
    "   b=pd.DataFrame(params,index=[0])\n",
    "   b=b.assign( val_score=val_score) \n",
    "   history_df=pd.concat([history_df,b])\n",
    "\n",
    "history_df=history_df.sort_values(by = 'val_score', ascending=False)\n",
    "a\n",
    "Soil_Export= 'C:/Users/user/Google Drive/TCD20/python/final_project/csv' \n",
    "history_df.to_csv(os.path.join(Soil_Export,'optimization.csv'))\n",
    "history_df\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00536600-8cae-491a-9d83-a4f8ca92f47b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Summary model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7924b7c0-4a75-4de1-9091-4e97857574e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the best model from the grid search\n",
    "best_model = grid_search.best_estimator_.model\n",
    "\n",
    "\n",
    "labels=['Black Soil', 'Cinder Soil', 'Laterite Soil', 'Peat Soil', 'Yellow Soil']\n",
    "labels=[0,1,2,3,4]\n",
    "\n",
    "classification_report1,confusion_matrix1,multi_confusion_matrix1=model_predict(best_model,X_test,y_test,labels)\n",
    "classification_report_df, dict_matrix, confusion_matrix_df=model_summary(classification_report1,multi_confusion_matrix1,confusion_matrix1,labels)\n",
    "f=plot_model_results(history_df)\n",
    "Soil_Export= 'C:/Users/user/Google Drive/TCD20/python/final_project/fig'       \n",
    "f.savefig(os.path.join(Soil_Export,'soil_image_dl_optimization.png'))      \n",
    "\n",
    "\n",
    "#classification_report_df\n",
    "print('### Yellow Soil ###')\n",
    "print(dict_matrix['Yellow Soil'])\n",
    "print('### Laterite Soil\t ###')\n",
    "print(dict_matrix['Laterite Soil'])\n",
    "print('### Black Soil ###')\n",
    "print(dict_matrix['Black Soil'])\n",
    "print('### Cinder Soill\t ###')\n",
    "print(dict_matrix['Cinder Soil'])\n",
    "print('### Peat Soil\t ###')\n",
    "print(dict_matrix['Peat Soil'])\n",
    "\n",
    "\n",
    "print(confusion_matrix_df)\n",
    "Soil_Export= 'C:/Users/user/Google Drive/TCD20/python/final_project/csv'   \n",
    "classification_report_df.to_csv(os.path.join(Soil_Export,'soil_image_dl_optimization.csv'))\n",
    "classification_report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804b5e4-e251-49a1-b08b-d71d2eeb807f",
   "metadata": {},
   "source": [
    "# inport the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c540d7fc-4582-4195-9db0-131ff4237eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_dir= 'C:/Users/user/Google Drive/TCD20/python/dataset/Soil types'\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "train_ds= tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "class_names =train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds_predict = val_ds.map(lambda x, y: (x / 255.0, y))\n",
    "y_train= []\n",
    "for images, labels in train_ds:\n",
    "    y_train.extend(labels.numpy())\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "y_test = []\n",
    "for images, labels in val_ds:\n",
    "    y_test.extend(labels.numpy())\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d13617-1c49-4621-91ef-dd25aba866bd",
   "metadata": {},
   "source": [
    "# from  image   Convolutional Neural Networks (CNNs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2e44a-045c-407c-924b-493d392ec2c8",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "### Set up the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e6200d-68bd-4433-b31b-5f51154627cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy,SparseCategoricalCrossentropy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_CNNmodel():                      \n",
    "    model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(5,activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model=create_CNNmodel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f7f33-02dc-46f7-bb57-d13675f9f4aa",
   "metadata": {},
   "source": [
    "## Compile ane fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24144bf2-f0e4-41fb-b576-89869828f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=create_CNNmodel()\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor (e.g., validation loss)\n",
    "    patience=3,  # Number of epochs to wait for improvement\n",
    "    restore_best_weights=True  # Restores the weights of the best epoch\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "epochs=20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  callbacks=[early_stopping_monitor]  # Include the EarlyStopping callback  \n",
    ")\n",
    "\n",
    "history_df=pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38250c3f-6845-4471-9ae5-0ea6c2947757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec04257b-b206-4f60-a2aa-71e01d00ea1b",
   "metadata": {},
   "source": [
    "### Summary model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c0a179-efaf-4656-9c71-2839448dc354",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[0,1,2,3,4]\n",
    "classification_report1,confusion_matrix1,multi_confusion_matrix1=model_predict(model,val_ds, y_test,labels)\n",
    "classification_report_df, dict_matrix, confusion_matrix_df=model_summary(classification_report1,multi_confusion_matrix1,confusion_matrix1,labels)\n",
    "f=plot_model_results(history_df)\n",
    "Soil_Export= 'C:/Users/user/Google Drive/TCD20/python/final_project/fig'       \n",
    "f.savefig(os.path.join(Soil_Export,'soil_image_dl_2.png'))      \n",
    "\n",
    "\n",
    "\n",
    "print(classification_report_df)\n",
    "print(confusion_matrix_df)\n",
    "print(dict_matrix['Yellow Soil'])\n",
    "Soil_Export= 'C:/Users/user/Google Drive/TCD20/python/final_project/csv'   \n",
    "classification_report_df.to_csv(os.path.join(Soil_Export,'soil_image_dl_2.csv'))\n",
    "\n",
    "classification_report_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e3a5f-22d8-40f4-9383-9701a6c9a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    #tf.keras.layers.RandomCrop(\n",
    "    #35,5, seed=12),\n",
    "\n",
    "    layers.RandomRotation(0.5),\n",
    "    layers.RandomZoom(0.5),\n",
    "  ]\n",
    ")\n",
    "\n",
    "#data_augmentation = tf.keras.Sequential([\n",
    "  #layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  #layers.RandomRotation(0.1),\n",
    "#])\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.Resizing(180, 180),\n",
    "  layers.Rescaling(1./255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5a23c-9021-4201-93a8-777d69d4707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(22):\n",
    "    print(_)\n",
    "    for i in range(5):\n",
    "     augmented_images = data_augmentation(images)\n",
    "     ax = plt.subplot(3, 3, i + 1)\n",
    "     plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "     plt.axis(\"off\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8451e-cc5d-4a87-a66e-5d9f811bc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  data_augmentation,  \n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(5)\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94dd195-ddbf-41bc-8b03-a0253e785564",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.summary()\n",
    "\n",
    "epochs=20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n",
    "\n",
    "history_df=pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18969dd-c5dd-40f1-ad32-0fa6e33f75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[0,1,2,3,4]\n",
    "classification_report1,confusion_matrix1,multi_confusion_matrix1=model_predict(model,val_ds, y_test,labels)\n",
    "classification_report_df, dict_matrix, confusion_matrix_df=model_summary(classification_report1,multi_confusion_matrix1,confusion_matrix1,labels)\n",
    "f=plot_model_results(history_df)\n",
    "Soil_Export= 'C:/Users/user/Google Drive/TCD20/python/final_project/fig'       \n",
    "f.savefig(os.path.join(Soil_Export,'soil_image_dl_3.png'))      \n",
    "\n",
    "\n",
    "\n",
    "print(classification_report_df)\n",
    "print(confusion_matrix_df)\n",
    "print(dict_matrix['Yellow Soil'])\n",
    "Soil_Export= 'C:/Users/user/Google Drive/TCD20/python/final_project/csv'   \n",
    "classification_report_df.to_csv(os.path.join(Soil_Export,'soil_image_dl_3.csv'))\n",
    "classification_report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52437f-44fe-46cb-b46f-107c72ee8d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed405e4c-7f90-4b03-82ec-514aa2d986de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91631f93-1967-4bc0-8f53-675e034cb48c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
